substitutions:
  _REGION: 'us-central1'
  _TABLE: 'sharedproejcet-1:dataflow.employe'
steps:
  # Step 1: Terraform Apply
  - name: hashicorp/terraform:light
    dir: terraform
    entrypoint: sh
    args:
      - "-c"
      - |
        terraform init
        terraform apply -auto-approve


  # Step 2: Run Dataflow Job
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: bash
    args:
      - '-c'
      - |
        gcloud dataflow jobs run dataflow-job \
          --gcs-location gs://dataflow-templates-us-central1/latest/GCS_Text_to_BigQuery \
          --region $_REGION \
          --staging-location gs://myworkspace-579raj/temp/ \
          --parameters inputFilePattern=gs://myworkspace-579raj/user.csv,JSONPath=gs://myworkspace-579raj/bq.json,outputTable=$_TABLE,bigQueryLoadingTemporaryDirectory=gs://myworkspace-579raj/,javascriptTextTransformGcsPath=gs://myworkspace-579raj/udf.js,javascriptTextTransformFunctionName=transform


# steps:
#   # Step 1: Deploy Terraform infrastructure
#   # - name: 'hashicorp/terraform'
#   #   entrypoint: 'sh'
#   #   args:
#   #     - '-c'
#   #     - |
#   #       terraform -chdir=terraform init
#   #       terraform -chdir=terraform apply -auto-approve
  
#   # Step 2: Build and deploy Dataflow Flex Template
#   - name: 'gcr.io/cloud-builders/gcloud'
#     args:
#       - dataflow
#       - flex-template
#       - build
#       - gs://getwellsoon-bucket/templates/streaming_template.json
#       - --sdk-language=PYTHON
#       - --flex-template-base-image=gcr.io/dataflow-templates-base/python3
#       - --metadata-file=gs://getwellsoon-bucket/staging/dataflow_template/metadata.json
#       - --python-package-gcs-uri=gs://getwellsoon-bucket/staging/dataflow_template
#       - --temp-location=gs://getwellsoon-bucket/temp

# timeout: 1200s
logsBucket: 'gs://myworkspace-579raj'
